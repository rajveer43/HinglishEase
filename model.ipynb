{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nCreate a Hinglish translation from English text. The text should sound natural and also\\nconvert all the difficult words and phrases in English to Hinglish. This converted text should\\nbe easy to understand for even a non-native Hindi speaker.\\nWe have attached below the statements that are required to be used for this assignment.\\n1. Definitely share your feedback in the comment section.\\n2. So even if it's a big video, I will clearly mention all the products.\\n3. I was waiting for my bag.\\nExample:\\nStatement: I had about a 30 minute demo just using this new headset\\nOutput required: मझु ेसि र्फ ३० minute का demo मि ला था इस नयेheadset का इस्तमे ाल करनेके\\nलि ए\\nRules:\\n● The model must be able to generate a translation that is indistinguishable from\\nHindi spoken by a casual Hindi speaker.\\n● Must be able to keep certain words in English to keep the Hindi translation Easy.\\n● The Hinglish sentences should be accurate to the meaning of the original sentence\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create a Hinglish translation from English text. The text should sound natural and also\n",
    "convert all the difficult words and phrases in English to Hinglish. This converted text should\n",
    "be easy to understand for even a non-native Hindi speaker.\n",
    "We have attached below the statements that are required to be used for this assignment.\n",
    "1. Definitely share your feedback in the comment section.\n",
    "2. So even if it's a big video, I will clearly mention all the products.\n",
    "3. I was waiting for my bag.\n",
    "Example:\n",
    "Statement: I had about a 30 minute demo just using this new headset\n",
    "Output required: मझु ेसि र्फ ३० minute का demo मि ला था इस नयेheadset का इस्तमे ाल करनेके\n",
    "लि ए\n",
    "Rules:\n",
    "● The model must be able to generate a translation that is indistinguishable from\n",
    "Hindi spoken by a casual Hindi speaker.\n",
    "● Must be able to keep certain words in English to keep the Hindi translation Easy.\n",
    "● The Hinglish sentences should be accurate to the meaning of the original sentence\n",
    "\"\"\"\n",
    "\n",
    "#use MT5 model for this\n",
    "#use pretrained model\n",
    "#use hinglish data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import nltk.translate.bleu_score as bleu\n",
    "import random\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "      <th>Hinglish</th>\n",
       "      <th>Average rating</th>\n",
       "      <th>Disagreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Program module is a file that contains instruc...</td>\n",
       "      <td>माड्यूल, एक संचिका होती है, जिसमें या तो स्रोत...</td>\n",
       "      <td>module , ek program hoti hai , jismen ya to so...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And to Thamud We sent their brother Sali 'h. H...</td>\n",
       "      <td>और (हमने) क़ौमे समूद के पास उनके भाई सालेह को ...</td>\n",
       "      <td>aur hamne aume samood ke pas unke bhaee saleh ...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and, when reminded, do not remember\\n</td>\n",
       "      <td>और जब उन्हें याद दिलाया जाता है, तो वे याद नही...</td>\n",
       "      <td>aur jab unhen yad dilaya jata hai , to ve yad ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you won the TED Prize 2011.\\n</td>\n",
       "      <td>तुम्हें २०११ का टेड प्राइज़ मिल गया है.\\n</td>\n",
       "      <td>tumhen २०११ ka ted prize mil gaya hai\\n</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He gone to Kerodemal College of Delhi Universi...</td>\n",
       "      <td>उन्होंने बाद अध्ययन करने के लिए ये दिल्ली विश्...</td>\n",
       "      <td>unhonne bad science karne ke lie ye delhi univ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English   \n",
       "0  Program module is a file that contains instruc...  \\\n",
       "1  And to Thamud We sent their brother Sali 'h. H...   \n",
       "2              and, when reminded, do not remember\\n   \n",
       "3                      you won the TED Prize 2011.\\n   \n",
       "4  He gone to Kerodemal College of Delhi Universi...   \n",
       "\n",
       "                                               Hindi   \n",
       "0  माड्यूल, एक संचिका होती है, जिसमें या तो स्रोत...  \\\n",
       "1  और (हमने) क़ौमे समूद के पास उनके भाई सालेह को ...   \n",
       "2  और जब उन्हें याद दिलाया जाता है, तो वे याद नही...   \n",
       "3          तुम्हें २०११ का टेड प्राइज़ मिल गया है.\\n   \n",
       "4  उन्होंने बाद अध्ययन करने के लिए ये दिल्ली विश्...   \n",
       "\n",
       "                                            Hinglish  Average rating   \n",
       "0  module , ek program hoti hai , jismen ya to so...               7  \\\n",
       "1  aur hamne aume samood ke pas unke bhaee saleh ...               6   \n",
       "2  aur jab unhen yad dilaya jata hai , to ve yad ...              10   \n",
       "3            tumhen २०११ ka ted prize mil gaya hai\\n               9   \n",
       "4  unhonne bad science karne ke lie ye delhi univ...               7   \n",
       "\n",
       "   Disagreement  \n",
       "0             6  \n",
       "1             4  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/synthetic-dataset/train.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average rating</th>\n",
       "      <th>Disagreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2766.000000</td>\n",
       "      <td>2766.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.015184</td>\n",
       "      <td>2.202820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.611146</td>\n",
       "      <td>1.885437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Average rating  Disagreement\n",
       "count     2766.000000   2766.000000\n",
       "mean         7.015184      2.202820\n",
       "std          1.611146      1.885437\n",
       "min          2.000000      0.000000\n",
       "25%          6.000000      1.000000\n",
       "50%          7.000000      2.000000\n",
       "75%          8.000000      3.000000\n",
       "max         10.000000      9.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "      <th>Hinglish</th>\n",
       "      <th>Average rating</th>\n",
       "      <th>Disagreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Program module is a file that contains instruc...</td>\n",
       "      <td>माड्यूल, एक संचिका होती है, जिसमें या तो स्रोत...</td>\n",
       "      <td>module , ek program hoti hai , jismen ya to so...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And to Thamud We sent their brother Sali 'h. H...</td>\n",
       "      <td>और (हमने) क़ौमे समूद के पास उनके भाई सालेह को ...</td>\n",
       "      <td>aur hamne aume samood ke pas unke bhaee saleh ...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and, when reminded, do not remember\\n</td>\n",
       "      <td>और जब उन्हें याद दिलाया जाता है, तो वे याद नही...</td>\n",
       "      <td>aur jab unhen yad dilaya jata hai , to ve yad ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you won the TED Prize 2011.\\n</td>\n",
       "      <td>तुम्हें २०११ का टेड प्राइज़ मिल गया है.\\n</td>\n",
       "      <td>tumhen २०११ ka ted prize mil gaya hai\\n</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He gone to Kerodemal College of Delhi Universi...</td>\n",
       "      <td>उन्होंने बाद अध्ययन करने के लिए ये दिल्ली विश्...</td>\n",
       "      <td>unhonne bad science karne ke lie ye delhi univ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>Polar ice caps may melt further and increase t...</td>\n",
       "      <td>अधिक मात्रा में ध्रुवों की बर्फ पिघलने से सागर...</td>\n",
       "      <td>large size men polar ki barph pighalne se ocea...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>It ' s what turns lead into gold , and makes t...</td>\n",
       "      <td>यही चक्र सीसे को सोना बना देता है , और सोने को...</td>\n",
       "      <td>yahi chakr lead into gold bana deta hai , aur ...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>The President said the North Eastern Hill Univ...</td>\n",
       "      <td>राष्ट्रपति ने कहा कि पूर्वोत्तर पर्वतीय विश्वव...</td>\n",
       "      <td>president ne kaha ki north parvtiy university ...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>The violin bow might well have grown out of th...</td>\n",
       "      <td>बहुत संभव है कि वायलिन का गज भी एक छड़ी को दूस...</td>\n",
       "      <td>bahut snbhav hai ki vaylin ka gaj bhi ek chhar...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>In fact, clans or families which succeeded in ...</td>\n",
       "      <td>वास्तव में सरदार का पद जीतनेवाले वंशों या परिव...</td>\n",
       "      <td>vastav men sardar ka pad jitnevale vnshon ya p...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2766 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                English   \n",
       "0     Program module is a file that contains instruc...  \\\n",
       "1     And to Thamud We sent their brother Sali 'h. H...   \n",
       "2                 and, when reminded, do not remember\\n   \n",
       "3                         you won the TED Prize 2011.\\n   \n",
       "4     He gone to Kerodemal College of Delhi Universi...   \n",
       "...                                                 ...   \n",
       "2761  Polar ice caps may melt further and increase t...   \n",
       "2762  It ' s what turns lead into gold , and makes t...   \n",
       "2763  The President said the North Eastern Hill Univ...   \n",
       "2764  The violin bow might well have grown out of th...   \n",
       "2765  In fact, clans or families which succeeded in ...   \n",
       "\n",
       "                                                  Hindi   \n",
       "0     माड्यूल, एक संचिका होती है, जिसमें या तो स्रोत...  \\\n",
       "1     और (हमने) क़ौमे समूद के पास उनके भाई सालेह को ...   \n",
       "2     और जब उन्हें याद दिलाया जाता है, तो वे याद नही...   \n",
       "3             तुम्हें २०११ का टेड प्राइज़ मिल गया है.\\n   \n",
       "4     उन्होंने बाद अध्ययन करने के लिए ये दिल्ली विश्...   \n",
       "...                                                 ...   \n",
       "2761  अधिक मात्रा में ध्रुवों की बर्फ पिघलने से सागर...   \n",
       "2762  यही चक्र सीसे को सोना बना देता है , और सोने को...   \n",
       "2763  राष्ट्रपति ने कहा कि पूर्वोत्तर पर्वतीय विश्वव...   \n",
       "2764  बहुत संभव है कि वायलिन का गज भी एक छड़ी को दूस...   \n",
       "2765  वास्तव में सरदार का पद जीतनेवाले वंशों या परिव...   \n",
       "\n",
       "                                               Hinglish  Average rating   \n",
       "0     module , ek program hoti hai , jismen ya to so...               7  \\\n",
       "1     aur hamne aume samood ke pas unke bhaee saleh ...               6   \n",
       "2     aur jab unhen yad dilaya jata hai , to ve yad ...              10   \n",
       "3               tumhen २०११ ka ted prize mil gaya hai\\n               9   \n",
       "4     unhonne bad science karne ke lie ye delhi univ...               7   \n",
       "...                                                 ...             ...   \n",
       "2761  large size men polar ki barph pighalne se ocea...               6   \n",
       "2762  yahi chakr lead into gold bana deta hai , aur ...               7   \n",
       "2763  president ne kaha ki north parvtiy university ...               8   \n",
       "2764  bahut snbhav hai ki vaylin ka gaj bhi ek chhar...               5   \n",
       "2765  vastav men sardar ka pad jitnevale vnshon ya p...               8   \n",
       "\n",
       "      Disagreement  \n",
       "0                6  \n",
       "1                4  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  \n",
       "...            ...  \n",
       "2761             4  \n",
       "2762             1  \n",
       "2763             4  \n",
       "2764             3  \n",
       "2765             4  \n",
       "\n",
       "[2766 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hinglish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Program module is a file that contains instruc...</td>\n",
       "      <td>module , ek program hoti hai , jismen ya to so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And to Thamud We sent their brother Sali 'h. H...</td>\n",
       "      <td>aur hamne aume samood ke pas unke bhaee saleh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and, when reminded, do not remember\\n</td>\n",
       "      <td>aur jab unhen yad dilaya jata hai , to ve yad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you won the TED Prize 2011.\\n</td>\n",
       "      <td>tumhen २०११ ka ted prize mil gaya hai\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He gone to Kerodemal College of Delhi Universi...</td>\n",
       "      <td>unhonne bad science karne ke lie ye delhi univ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english   \n",
       "0  Program module is a file that contains instruc...  \\\n",
       "1  And to Thamud We sent their brother Sali 'h. H...   \n",
       "2              and, when reminded, do not remember\\n   \n",
       "3                      you won the TED Prize 2011.\\n   \n",
       "4  He gone to Kerodemal College of Delhi Universi...   \n",
       "\n",
       "                                            hinglish  \n",
       "0  module , ek program hoti hai , jismen ya to so...  \n",
       "1  aur hamne aume samood ke pas unke bhaee saleh ...  \n",
       "2  aur jab unhen yad dilaya jata hai , to ve yad ...  \n",
       "3            tumhen २०११ ka ted prize mil gaya hai\\n  \n",
       "4  unhonne bad science karne ke lie ye delhi univ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new dataframe of english and hinglish column\n",
    "df = pd.DataFrame()\n",
    "df['english'] = dataset['English']\n",
    "df['hinglish'] = dataset['Hinglish']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "remove_digits = str.maketrans('', '', string.digits) # Set of all digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write function to preprocess english sentence\n",
    "def preprocess_english_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\"'\", '', sentence)\n",
    "    sentence = ''.join(ch for ch in sentence if ch not in exclude)\n",
    "    sentence = sentence.translate(remove_digits)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub(\" +\", \" \", sentence)\n",
    "    sentence = '<start> ' + sentence + ' <end>'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess hinglish sentense\n",
    "def preprocess_hinglish_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\"'\", '', sentence)\n",
    "    sentence = ''.join(ch for ch in sentence if ch not in exclude)\n",
    "    sentence = sentence.translate(remove_digits)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub(\" +\", \" \", sentence)\n",
    "    sentence = '<start> ' + sentence + ' <end>'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hinglish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; program module is a file that contains...</td>\n",
       "      <td>&lt;start&gt; module ek program hoti hai jismen ya t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; and to thamud we sent their brother sa...</td>\n",
       "      <td>&lt;start&gt; aur hamne aume samood ke pas unke bhae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; and when reminded do not remember &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; aur jab unhen yad dilaya jata hai to v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; you won the ted prize &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; tumhen २०११ ka ted prize mil gaya hai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; he gone to kerodemal college of delhi ...</td>\n",
       "      <td>&lt;start&gt; unhonne bad science karne ke lie ye de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english   \n",
       "0  <start> program module is a file that contains...  \\\n",
       "1  <start> and to thamud we sent their brother sa...   \n",
       "2    <start> and when reminded do not remember <end>   \n",
       "3                <start> you won the ted prize <end>   \n",
       "4  <start> he gone to kerodemal college of delhi ...   \n",
       "\n",
       "                                            hinglish  \n",
       "0  <start> module ek program hoti hai jismen ya t...  \n",
       "1  <start> aur hamne aume samood ke pas unke bhae...  \n",
       "2  <start> aur jab unhen yad dilaya jata hai to v...  \n",
       "3  <start> tumhen २०११ ka ted prize mil gaya hai ...  \n",
       "4  <start> unhonne bad science karne ke lie ye de...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['english'] = df['english'].apply(preprocess_english_sentence)\n",
    "df['hinglish'] = df['hinglish'].apply(preprocess_hinglish_sentence)\n",
    "\n",
    "df.rename(columns={\"english_sentence\": \"english\", \"hindi_sentence\": \"hindi\"},inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenzizer\n",
    "def tokenizer(language):\n",
    "    tokenizer = Tokenizer(filters='', split=\" \")\n",
    "    tokenizer.fit_on_texts(language)\n",
    "    tensor = tokenizer.texts_to_sequences(language)\n",
    "    tensor = pad_sequences(tensor, padding='post')\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    input_tensor, inp_lang_tokenizer = tokenizer(df['english'].values)\n",
    "    target_tensor, targ_lang_tokenizer = tokenizer(df['hinglish'].values)\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, target_tensor, input_lang, target_lang = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2212 2212 554 554\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "\n",
    "vocab_inp_size =len(input_lang.word_index.keys())\n",
    "vocab_tar_size =len(target_lang.word_index.keys())\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove-2.txt',\"r+\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_inp_size+1, 300))\n",
    "for word, i in input_lang.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, name=\"embedding_layer_encoder\",trainable=False)\n",
    "        self.gru = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_activation='sigmoid', recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_activation='sigmoid', recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "                # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        \n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "encoder = Encoder(vocab_inp_size+1, 300, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size+1, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                            reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "    encoder.get_layer('embedding_layer_encoder').set_weights([embedding_matrix])\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([target_lang.word_index['']] * BATCH_SIZE, 1)\n",
    "\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m (batch, (inp, targ)) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataset\u001b[39m.\u001b[39mtake(steps_per_epoch)):\n\u001b[1;32m---> 10\u001b[0m   batch_loss \u001b[39m=\u001b[39m train_step(inp, targ, enc_hidden)\n\u001b[0;32m     11\u001b[0m   total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\n\u001b[0;32m     13\u001b[0m   \u001b[39mif\u001b[39;00m batch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "  print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
    "  print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m (batch, (inp, targ)) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataset\u001b[39m.\u001b[39mtake(steps_per_epoch)):\n\u001b[1;32m----> 8\u001b[0m   batch_loss \u001b[39m=\u001b[39m train_step(inp, targ, enc_hidden)\n\u001b[0;32m      9\u001b[0m   total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\n\u001b[0;32m     11\u001b[0m   \u001b[39mif\u001b[39;00m batch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCHS,20):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "  print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
    "  print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=20, padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '':\n",
    "      return result,attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result,attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence in english :  please ensure that you use the appropriate form \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m input_sentence\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mplease ensure that you use the appropriate form \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mInput sentence in english : \u001b[39m\u001b[39m'\u001b[39m,input_sentence)\n\u001b[1;32m----> 3\u001b[0m predicted_output,attention_plot\u001b[39m=\u001b[39mevaluate(input_sentence)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPredicted sentence in hindi : \u001b[39m\u001b[39m'\u001b[39m,predicted_output)\n",
      "Cell \u001b[1;32mIn[44], line 4\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(sentence):\n\u001b[0;32m      2\u001b[0m   attention_plot \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((max_length_targ, max_length_inp))\n\u001b[1;32m----> 4\u001b[0m   sentence \u001b[39m=\u001b[39m preprocess(sentence)\n\u001b[0;32m      6\u001b[0m   inputs \u001b[39m=\u001b[39m [inp_lang\u001b[39m.\u001b[39mword_index[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m sentence\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m      7\u001b[0m   inputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mpreprocessing\u001b[39m.\u001b[39msequence\u001b[39m.\u001b[39mpad_sequences([inputs],maxlen\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "input_sentence= 'please ensure that you use the appropriate form '\n",
    "print('Input sentence in english : ',input_sentence)\n",
    "predicted_output,attention_plot=evaluate(input_sentence)\n",
    "print('Predicted sentence in hindi : ',predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_sentence='and do something with it to change the world '\n",
    "print('Input sentence in english : ',input_sentence)\n",
    "predicted_output,attention_plot=evaluate(input_sentence)\n",
    "print('Predicted sentence in hindi : ',predicted_output)\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
